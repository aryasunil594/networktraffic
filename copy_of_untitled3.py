# -*- coding: utf-8 -*-
"""Copy of Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JGKAbG2-Hf55a802FtkMqto5OxsxcjL-
"""

from tensorflow import keras
from tensorflow.keras import layers
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest  # Import Isolation Forest

# Load the synthetic dataset
data = pd.read_csv('/content/synthetic_network_traffic.csv')  # Adjust the path as needed

# Display dataset information
print(data.info())

# Display first few rows
print(data.head())

# Feature Engineering: Generate additional features
data['TotalBytes'] = data['BytesSent'] + data['BytesReceived']
data['TotalPackets'] = data['PacketsSent'] + data['PacketsReceived']

# Oversample the 'Anomaly' class to balance the class distribution
anomaly_data = data[data['IsAnomaly'] == 1]
oversampled_data = pd.concat([data, anomaly_data], axis=0)

# Split the dataset into features and labels
X = oversampled_data.drop(columns=['IsAnomaly'])  # Features
y = oversampled_data['IsAnomaly']  # Labels

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train Isolation Forest model
isolation_forest = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)
isolation_forest.fit(X_train)

iso_forest = IsolationForest(contamination=0.05, random_state=42)
iso_forest.fit(X_train)
y_pred_iso = iso_forest.predict(X_test)
y_pred_iso = [1 if p == -1 else 0 for p in y_pred_iso]

def create_model():
    model = keras.Sequential([
        layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
        layers.Dense(64, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

model = create_model()
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# Evaluate models
print("Isolation Forest Results:")
print(classification_report(y_test, y_pred_iso))

# Predict anomalies
y_pred_train = isolation_forest.predict(X_train)
y_pred_test = isolation_forest.predict(X_test)

# Convert predictions (-1 means anomaly, 1 means normal)
y_pred_train = np.where(y_pred_train == -1, 1, 0)
y_pred_test = np.where(y_pred_test == -1, 1, 0)

# Classification Report
print("Classification Report (Test Data):")
print(classification_report(y_test, y_pred_test))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred_test)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_test)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic (ROC) Curve")
plt.legend()
plt.show()

import joblib
joblib.dump(isolation_forest, "isolation_forest_model.pkl")

from flask import Flask, request, jsonify
import joblib
import numpy as np

app = Flask(__name__)
model = joblib.load("/content/isolation_forest_model.pkl")  # Load trained model

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json['features']  # Receive input data
    prediction = model.predict(np.array(data).reshape(1, -1))  # Predict anomaly
    return jsonify({'anomaly': int(prediction[0])})  # Return result

if __name__ == '__main__':
    app.run(debug=True)

import pandas as pd  # Make sure pandas is imported
new_network_traffic = pd.read_csv("/content/synthetic_network_traffic.csv")

# Assuming you have new_network_traffic loaded
new_network_traffic['TotalBytes'] = new_network_traffic['BytesSent'] + new_network_traffic['BytesReceived']
new_network_traffic['TotalPackets'] = new_network_traffic['PacketsSent'] + new_network_traffic['PacketsReceived']

# Drop the "IsAnomaly" column if it's present in the new data
if 'IsAnomaly' in new_network_traffic.columns:
    new_network_traffic = new_network_traffic.drop(columns=['IsAnomaly'])

# Now scale the data:
new_data_scaled = scaler.transform(new_network_traffic)

# And make predictions:
new_predictions = model.predict(new_data_scaled)

new_data_scaled = scaler.transform(new_network_traffic)
new_predictions = model.predict(new_data_scaled)

model = joblib.load("isolation_forest_model.pkl")
new_predictions = model.predict(new_data_scaled)  # Replace 'new_data' with real input

import pandas as pd

# Load new network traffic data (CSV, Excel, etc.)
new_data = pd.read_csv("/content/synthetic_network_traffic.csv")  # Change filename accordingly

# Apply the same preprocessing steps as before
X_new = new_data.drop(["IsAnomaly"], axis=1)  # Replace 'IsAnomaly' with the correct column name

X_new['TotalBytes'] = X_new['BytesSent'] + X_new['BytesReceived']
X_new['TotalPackets'] = X_new['PacketsSent'] + X_new['PacketsReceived']

# Assuming you have X_new (the new data)

# Engineer the features that were engineered in the training data:
X_new['TotalBytes'] = X_new['BytesSent'] + X_new['BytesReceived']
X_new['TotalPackets'] = X_new['PacketsSent'] + X_new['PacketsReceived']

# Scale the data using the same scaler used in training:
X_new_scaled = scaler.transform(X_new)

# Now make predictions using the model:
y_pred_if = isolation_forest.predict(X_new_scaled)

# ... (rest of your code)

y_pred_if = isolation_forest.predict(X_new)

# Convert (-1 to 1) → anomaly, (1 to 0) → normal
y_pred_if = [1 if x == -1 else 0 for x in y_pred_if]

# Show predictions
print("Isolation Forest Predictions:", y_pred_if)

import pandas as pd

# Assuming y_pred_if contains the predictions (0 for normal, 1 for anomaly)

# Create a Pandas Series for easier manipulation
predictions_series = pd.Series(y_pred_if, name="Anomaly Detection Predictions")

# Count the occurrences of each prediction (0 and 1)
prediction_counts = predictions_series.value_counts()

# Print the counts:
print("Anomaly Detection Prediction Counts:")
print(prediction_counts)

# Optionally, print the percentage of anomalies:
anomaly_percentage = (prediction_counts.get(1, 0) / len(predictions_series)) * 100
print(f"\nPercentage of Anomalies: {anomaly_percentage:.2f}%")

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 4))
sns.histplot(y_pred_if, label="Isolation Forest", kde=True, color="blue", alpha=0.6)
plt.legend()
plt.title("Anomaly Detection Predictions")
plt.xlabel("Anomaly (1) vs Normal (0)")
plt.ylabel("Frequency")
plt.show()